{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pulling Papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/degn400/.virtualenvs/DancePartner/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-04-24 10:47:29 WE45748 metapub.config[19799] WARNING NCBI_API_KEY was not set.\n"
     ]
    }
   ],
   "source": [
    "# Load Libraries\n",
    "import os\n",
    "import shutil\n",
    "import DancePartner as dance\n",
    "import pandas as pd\n",
    "\n",
    "# Define the output directory\n",
    "output_directory = os.path.join(os.getcwd(), \"pulling_papers\")\n",
    "\n",
    "# Remove it if it already exists and start anew\n",
    "if os.path.exists(output_directory):\n",
    "    shutil.rmtree(output_directory)\n",
    "    os.mkdir(output_directory, mode = 0o777)\n",
    "else: \n",
    "    os.mkdir(output_directory, mode = 0o777)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DancePartner can be used to pull papers from PubMed, Scopus, and OSTI. Papers can be pulled from databases individually, or multiple databases at a time. The default priority is clean text whenever possible followed by titles and abstracts. Users may specify different priorities when pulling text. \n",
    "\n",
    "Here we will go through various ways that publications can be pulled. Our examples are:\n",
    "\n",
    "1. Pulling papers from a single database\n",
    "2. Pulling papers from multiple databases\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: Pulling papers from a single database\n",
    "\n",
    "Here, we have a list of PubMed paper IDs that be either numeric or string type. The last ID does not reference a real paper, but demonstrates how the package acts when a paper is encountered that does not exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_ids = [9851916, 16803962, 12628183, 15035988, 17626846, 18675916, 21858180, 16803962333333]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we call our paper pulling function called `pull_papers`. Note that this function may take a while depending on the number of publications to pull. You should estimate approximately 1-5 seconds per publication. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 10:47:35 WE45748 metapub.findit[19799] INFO FindIt Cache initialized at /Users/degn400/.cache/findit.db\n"
     ]
    }
   ],
   "source": [
    "os.mkdir(os.path.join(output_directory, \"pubmed_paper_output_folder\"))\n",
    "dance.pull_papers(pubmed_ids = paper_ids, output_directory = os.path.join(output_directory, \"pubmed_paper_output_folder\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the content of the folder that we created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pubmed_tarballs',\n",
       " 'pubmed_clean',\n",
       " 'output_summary.txt',\n",
       " 'pubmed_abstracts',\n",
       " 'pubmed_pdfs']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(os.path.join(output_directory, \"pubmed_paper_output_folder\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the output folder contains an `output_summary.txt` file as well as several subdirectories. The `pubmed_tarballs` folder contains the `[].tar.gz` files that are used as a subprocess to collect full papers from the PubMed database. They are large files that do not need to be kept. If you would like to write them to a different location, you can specify this in `ppi.pull_papers()` with the optional `tarball_path` parameter. The other three subfolders contain the actual papers themselves. We can glean additional insight into these folders with the `output_summary.txt` file. Let's take a look at what it says:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Summary for Pulling Papers\n",
      "Created: 2025-04-24 10:47:45.759754\n",
      "Total Num. Articles: 8\n",
      "Total Num. Articles Found: 7\n",
      "Number of Full Text: 3\n",
      "Number of Title & Abstracts: 4\n",
      "Number Missing: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(output_directory, \"pubmed_paper_output_folder\", \"output_summary.txt\"), \"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives a detailed look at the results of the pull_paper function. It shows us when the files were downloaded, the database used, the total number of articles that were searched for, as well as a breakdown of how many papers of each download type were found. Users may also specify which publication type they would like to pull, whether that be \"abstracts\", \"full text\", or \"both\" where priority is given to full text publications. Let's pull some abstracts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Summary for Pulling Papers\n",
      "Created: 2025-04-24 10:47:50.005828\n",
      "Total Num. Articles: 8\n",
      "Total Num. Articles Found: 7\n",
      "Number of Full Text: 0\n",
      "Number of Title & Abstracts: 7\n",
      "Number Missing: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create directory to hold papers \n",
    "os.mkdir(os.path.join(output_directory, \"pubmed_abstracts\"))\n",
    "\n",
    "# Pull papers\n",
    "dance.pull_papers(pubmed_ids = paper_ids, output_directory = os.path.join(output_directory, \"pubmed_abstracts\"), type = \"abstract\")\n",
    "\n",
    "# Read summary file \n",
    "with open(os.path.join(output_directory, \"pubmed_abstracts\", \"output_summary.txt\"), \"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If using the output csv from LitPortal, read the table into python. For PubMed and OSTI, please use the `OriginId` column. For Scopus, please use the `DOI` column. Let's pull papers from scopus. Scopus requires an API key. Save the key as \"scopus_key.txt\" as put it in your example_data folder. More details can be found here: https://dev.elsevier.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Summary for Pulling Papers\n",
      "Created: 2025-04-24 10:47:53.884140\n",
      "Total Num. Articles: 4\n",
      "Total Num. Articles Found: 4\n",
      "Number of Full Text: 1\n",
      "Number of Title & Abstracts: 3\n",
      "Number Missing: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create directory to hold papers\n",
    "os.mkdir(os.path.join(output_directory, \"scopus_papers\"))\n",
    "\n",
    "# Read the scopus api key \n",
    "with open(os.path.join(os.getcwd(), \"../example_data/scopus_key.txt\"), \"r\" ) as f: \n",
    "    scopus_api_key = f.read()\n",
    "\n",
    "# Pull papers\n",
    "dance.pull_papers(scopus_ids = [\"10.1186/s40168-021-01035-8\", \"10.1002/bit.26296\", \"10.1002/pmic.200300397\", \"10.1074/mcp.M115.057117\"],\n",
    "                output_directory = os.path.join(output_directory, \"scopus_papers\"), scopus_api_key = scopus_api_key)\n",
    "\n",
    "# Read summary file \n",
    "with open(os.path.join(output_directory, \"scopus_papers\", \"output_summary.txt\"), \"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, here is an example using OSTI. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/degn400/.virtualenvs/DancePartner/lib/python3.9/site-packages/DancePartner/pull_osti.py:90: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 90 of the file /Users/degn400/.virtualenvs/DancePartner/lib/python3.9/site-packages/DancePartner/pull_osti.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  f.write(BeautifulSoup(data['title']).get_text() + \". \")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Summary for Pulling Papers\n",
      "Created: 2025-04-24 10:47:56.264270\n",
      "Total Num. Articles: 4\n",
      "Total Num. Articles Found: 3\n",
      "Number of Full Text: 0\n",
      "Number of Title & Abstracts: 3\n",
      "Number Missing: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create directory to hold osti papers\n",
    "os.mkdir(os.path.join(output_directory, \"osti_papers\"))\n",
    "\n",
    "# Pull papers\n",
    "dance.pull_papers(osti_ids = [\"2229172\", \"1629838\", \"1766618\", \"1379914\"], output_directory = os.path.join(output_directory, \"osti_papers\"))\n",
    "\n",
    "# Read summary file \n",
    "with open(os.path.join(output_directory, \"osti_papers\", \"output_summary.txt\"), \"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Pulling Papers from Multiple Databases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oftentimes, we want to pull papers from more than just one database. To do so, we pass a differnt set of arguments to our `pull_papers` function. Instead of specifying a database and a list of IDs, we can instead feed strings pointing to the CSV files downloaded from each database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import DancePartner as dance\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "pubmed_path = os.path.join(os.getcwd(), \"vignette_data/PubMed_Export.csv\")\n",
    "scopus_path = os.path.join(os.getcwd(), \"vignette_data/Scopus_Export.csv\")\n",
    "osti_path = os.path.join(os.getcwd(), \"vignette_data/OSTI_Export.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's deduplicate the papers with the deduplicate_papers function.\n",
    "\n",
    "We will now specify the output folder location as we did previously. Please note that using Scopus requires an API key to function properly. Instructions to obtain one can be found [here](https://dev.elsevier.com/). We will read in our key here, so remember to replace these lines with yours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "pubmed",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "DOI",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "scopus",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "osti",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Title",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "b16af982-0171-444b-a151-3cb2244ec991",
       "rows": [
        [
         "0",
         null,
         "10.1002/aic.16396",
         null,
         "1610933",
         null
        ],
        [
         "1",
         null,
         "10.1002/ange.202212074",
         null,
         "1894730",
         null
        ],
        [
         "2",
         null,
         "10.1002/anie.202212074",
         null,
         "1900267",
         null
        ],
        [
         "3",
         "15822095",
         "10.1002/arch.20053",
         null,
         null,
         null
        ],
        [
         "4",
         null,
         "10.1002/bies.202300188",
         null,
         "2376130",
         null
        ],
        [
         "5",
         null,
         "10.1002/btpr.3413",
         null,
         "2221867",
         null
        ],
        [
         "6",
         "12652602",
         "10.1002/elps.200390027",
         null,
         null,
         null
        ],
        [
         "7",
         "15726569",
         "10.1002/jcc.20192",
         null,
         null,
         null
        ],
        [
         "8",
         null,
         "10.1002/lno.12275",
         null,
         "1906733",
         null
        ],
        [
         "9",
         null,
         "10.1002/lno.12505",
         null,
         "2331323",
         null
        ],
        [
         "10",
         null,
         "10.1002/pld3.472",
         null,
         "1906762",
         null
        ],
        [
         "11",
         null,
         "10.1002/pld3.546",
         null,
         "2212828",
         null
        ],
        [
         "12",
         "12748944",
         "10.1002/pmic.200300390",
         null,
         null,
         null
        ],
        [
         "13",
         "12748954",
         "10.1002/pmic.200300397",
         null,
         null,
         null
        ],
        [
         "14",
         "12833530",
         "10.1002/pmic.200300403",
         null,
         null,
         null
        ],
        [
         "15",
         "12748956",
         "10.1002/pmic.200300416",
         null,
         null,
         null
        ],
        [
         "16",
         "12833531",
         "10.1002/pmic.200300418",
         null,
         null,
         null
        ],
        [
         "17",
         "12872237",
         "10.1002/pmic.200300430",
         null,
         null,
         null
        ],
        [
         "18",
         "15761956",
         "10.1002/pmic.200301088",
         null,
         null,
         null
        ],
        [
         "19",
         "15648048",
         "10.1002/pmic.200400984",
         null,
         null,
         null
        ],
        [
         "20",
         "15712242",
         "10.1002/pmic.200400989",
         null,
         null,
         null
        ],
        [
         "21",
         "15732134",
         "10.1002/pmic.200400994",
         null,
         null,
         null
        ],
        [
         "22",
         "15717329",
         "10.1002/pmic.200401046",
         null,
         null,
         null
        ],
        [
         "23",
         "15693067",
         "10.1002/pmic.200401074",
         null,
         null,
         null
        ],
        [
         "24",
         null,
         "10.1002/pmic.201700034",
         "2-s2.0-85038264272",
         null,
         null
        ],
        [
         "25",
         null,
         "10.1002/pmic.201700300",
         "2-s2.0-85037979192",
         null,
         null
        ],
        [
         "26",
         null,
         "10.1002/pmic.202000072",
         "2-s2.0-85093668051",
         null,
         null
        ],
        [
         "27",
         null,
         "10.1002/pro.4443",
         null,
         "1890007",
         null
        ],
        [
         "28",
         null,
         "10.1002/pro.4600",
         null,
         "1962894",
         null
        ],
        [
         "29",
         null,
         "10.1002/pro.4848",
         null,
         "2263263",
         null
        ],
        [
         "30",
         "12784215",
         "10.1002/prot.10340",
         null,
         null,
         null
        ],
        [
         "31",
         "15657928",
         "10.1002/prot.20267",
         null,
         null,
         null
        ],
        [
         "32",
         "15616985",
         "10.1002/prot.20307",
         null,
         null,
         null
        ],
        [
         "33",
         "15617065",
         "10.1002/prot.20348",
         null,
         null,
         null
        ],
        [
         "34",
         null,
         "10.1007/978-1-0716-0962-0_6",
         "2-s2.0-85096458278",
         null,
         null
        ],
        [
         "35",
         null,
         "10.1007/978-1-0716-1186-9_22",
         "2-s2.0-85099721894",
         null,
         null
        ],
        [
         "36",
         null,
         "10.1007/978-1-0716-1186-9_6",
         "2-s2.0-85099721172",
         null,
         null
        ],
        [
         "37",
         null,
         "10.1007/978-1-4939-8695-8_14",
         "2-s2.0-85054180809",
         null,
         null
        ],
        [
         "38",
         "15791937",
         "10.1007/b98913",
         null,
         null,
         null
        ],
        [
         "39",
         "12655459",
         "10.1007/s00253-002-1202-6",
         null,
         null,
         null
        ],
        [
         "40",
         null,
         "10.1007/s00253-021-11169-2",
         "2-s2.0-85101771527",
         null,
         null
        ],
        [
         "41",
         null,
         "10.1007/s11120-023-01069-z",
         null,
         "2337951",
         null
        ],
        [
         "42",
         null,
         "10.1007/s12602-020-09671-6",
         "2-s2.0-85086384822",
         null,
         null
        ],
        [
         "43",
         null,
         "10.1007/s42770-019-00207-x",
         "2-s2.0-85077092037",
         null,
         null
        ],
        [
         "44",
         "15808222",
         "10.1016/S0076-6879(05)94008-1",
         null,
         null,
         null
        ],
        [
         "45",
         "12788544",
         "10.1016/S0167-7799(03)00113-6",
         null,
         null,
         null
        ],
        [
         "46",
         "12948670",
         "10.1016/S0167-7799(03)00189-6",
         null,
         null,
         null
        ],
        [
         "47",
         null,
         "10.1016/j.bbamem.2020.183488",
         "2-s2.0-85093662844",
         null,
         null
        ],
        [
         "48",
         null,
         "10.1016/j.bmc.2020.115901",
         "2-s2.0-85097775581",
         null,
         null
        ],
        [
         "49",
         null,
         "10.1016/j.bmcl.2021.127903",
         "2-s2.0-85102862672",
         null,
         null
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 293
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pubmed</th>\n",
       "      <th>DOI</th>\n",
       "      <th>scopus</th>\n",
       "      <th>osti</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10.1002/aic.16396</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1610933</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10.1002/ange.202212074</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1894730</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10.1002/anie.202212074</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1900267</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15822095</td>\n",
       "      <td>10.1002/arch.20053</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10.1002/bies.202300188</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2376130</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10.7554/eLife.87303</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2282793</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10.7554/elife.60049</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1825553</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10.7717/peerj.5245</td>\n",
       "      <td>2-s2.0-85050639015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>12934925</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>probing the molecular physiology of the microb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>12796811</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the phosphorylation of ns protein of wheat ros...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>293 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pubmed                     DOI              scopus     osti  \\\n",
       "0         NaN       10.1002/aic.16396                 NaN  1610933   \n",
       "1         NaN  10.1002/ange.202212074                 NaN  1894730   \n",
       "2         NaN  10.1002/anie.202212074                 NaN  1900267   \n",
       "3    15822095      10.1002/arch.20053                 NaN      NaN   \n",
       "4         NaN  10.1002/bies.202300188                 NaN  2376130   \n",
       "..        ...                     ...                 ...      ...   \n",
       "288       NaN     10.7554/eLife.87303                 NaN  2282793   \n",
       "289       NaN     10.7554/elife.60049                 NaN  1825553   \n",
       "290       NaN      10.7717/peerj.5245  2-s2.0-85050639015      NaN   \n",
       "291  12934925                     NaN                 NaN      NaN   \n",
       "292  12796811                     NaN                 NaN      NaN   \n",
       "\n",
       "                                                 Title  \n",
       "0                                                  NaN  \n",
       "1                                                  NaN  \n",
       "2                                                  NaN  \n",
       "3                                                  NaN  \n",
       "4                                                  NaN  \n",
       "..                                                 ...  \n",
       "288                                                NaN  \n",
       "289                                                NaN  \n",
       "290                                                NaN  \n",
       "291  probing the molecular physiology of the microb...  \n",
       "292  the phosphorylation of ns protein of wheat ros...  \n",
       "\n",
       "[293 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deduplicated_papers = dance.deduplicate_papers(pubmed_path, scopus_path, osti_path)\n",
    "deduplicated_papers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the deduped_table that is needed by pull_papers(). Papers will be pulled prioritizing full text to abstracts, in the order of pubmed, scopus, and OSTI. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/degn400/.virtualenvs/DancePartner/lib/python3.9/site-packages/DancePartner/pull_osti.py:90: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 90 of the file /Users/degn400/.virtualenvs/DancePartner/lib/python3.9/site-packages/DancePartner/pull_osti.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  f.write(BeautifulSoup(data['title']).get_text() + \". \")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Summary for Pulling Papers\n",
      "Created: 2025-04-24 10:48:02.478693\n",
      "Total Num. Articles: 20\n",
      "Total Num. Articles Found: 11\n",
      "Number of Full Text: 0\n",
      "Number of Title & Abstracts: 11\n",
      "Number Missing: 9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make an example for this deduplicated data \n",
    "os.mkdir(os.path.join(output_directory, \"deduped_example\"))\n",
    "\n",
    "# Read the scopus api key \n",
    "with open(os.path.join(os.getcwd(), \"../example_data/scopus_key.txt\"), \"r\" ) as f: \n",
    "    scopus_api_key = f.read()\n",
    "\n",
    "# To save time, let's do a subset of the deduplicated papers\n",
    "a_subset = pd.concat([deduplicated_papers.head(10), deduplicated_papers.tail(10)]).reset_index(drop = True)\n",
    "\n",
    "# Pull the papers. To save time, let's do the first 10 rows and the last 10 rows\n",
    "dance.pull_papers(deduped_table = a_subset, output_directory = os.path.join(output_directory, \"deduped_example\"), scopus_api_key = scopus_api_key)\n",
    "\n",
    "# Read summary file \n",
    "with open(os.path.join(output_directory, \"deduped_example\", \"output_summary.txt\"), \"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A note on adding publications. They must be added as txt files. The `pypdf` package can be used to convert a pdf to txt file using the `pdfReader()`. Example code is below\n",
    "\n",
    "```{python}\n",
    "# Load library\n",
    "import pypdf\n",
    "\n",
    "# Read data\n",
    "reader = PdfReader(\"your_file.pdf\")\n",
    "\n",
    "# Hold text\n",
    "text = []\n",
    "\n",
    "with open(\"your_file.txt\", \"w\") as file:\n",
    "    for page in reader.pages:\n",
    "        file.write(page.extract_text() + \"\\n\")\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DancePartner",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
